{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime \n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/FRED SHONE\n"
     ]
    }
   ],
   "source": [
    "# Set-up directory\n",
    "\n",
    "disk_name = 'FRED SHONE' # Memory Stick\n",
    "disk_location = '/Volumes'\n",
    "disk_path = os.path.join(disk_location, disk_name)\n",
    "print(disk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01-03-2015', '01-04-2015']\n"
     ]
    }
   ],
   "source": [
    "# Access daily sub-directories of images\n",
    "\n",
    "folders = sorted(os.listdir(disk_path)) # Assumes sorting by name is ok - but this won't work for changes in year\n",
    "\n",
    "# Filter for days by trying to convert to datetime\n",
    "\n",
    "day_directories = []\n",
    "for folder in folders:\n",
    "    try: \n",
    "        datetime.strptime(folder, '%m-%d-%Y')\n",
    "        day_directories.append(folder)\n",
    "    except: pass\n",
    "    \n",
    "print(day_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-03-2015: 16684 images\n",
      "frame rate assumed to be ~0.30896296296296294 frames per second\n",
      "01-04-2015: 16680 images\n",
      "frame rate assumed to be ~0.3088888888888889 frames per second\n"
     ]
    }
   ],
   "source": [
    "# Check for number of images in day directories\n",
    "\n",
    "for day_directory in day_directories:\n",
    "    day_dir_path = os.path.join(disk_path, day_directory)\n",
    "    image_paths = os.listdir(day_dir_path)\n",
    "    image_paths = sorted([image for image in os.listdir(day_dir_path) if not image.startswith('.')])\n",
    "    image_count = len(image_paths)\n",
    "    print('{}: {} images'.format(day_directory, image_count))   \n",
    "    #Wilkins building listed as opening hours from 8am to 11pm = 15 hours\n",
    "    frame_rate = image_count/(15*60*60)\n",
    "    print('frame rate assumed to be ~{} frames per second'.format(frame_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fredshone/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append('object_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'faster_rcnn_inception_v2_coco_2017_11_08'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fredshone/Projects/Dissertation\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0f44cc6cfe54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDOWNLOAD_BASE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMODEL_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtar_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtar_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmembers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     \u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocknum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/tempfile.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0m_functools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0;31m# Avoid closing the file as long as the wrapper is alive,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# see issue #18879.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Download Model\n",
    "opener = urllib.request.opener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Frozen model into memory\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set-up motion detector\n",
    "trigger = 0.0001 # Total pixel difference to trigger motion detection\n",
    "warning_trigger = 10000 # Total pixel difference to trigger verbose image plot\n",
    "\n",
    "verbose = False \n",
    "start_time = '08:00' # Assumes camera turned on at 8am every day\n",
    "frame_step = 3 # Seconds\n",
    "\n",
    "detect_objects = True\n",
    "detection_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigger_record = [] # Record of triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52411aa292e44d99d0f68278799f8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Days:', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85d874eab324b828c82b91a899302e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2015-01-03 00:00:00 progress:', max=16684), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 detections recorded at 2015-01-03 08:00:45\n",
      "person: 0.9367648363113403%\n",
      "3 detections recorded at 2015-01-03 08:01:36\n",
      "person: 0.99587482213974%\n",
      "person: 0.9759001135826111%\n",
      "person: 0.912125825881958%\n",
      "4 detections recorded at 2015-01-03 08:01:39\n",
      "person: 0.999408483505249%\n",
      "person: 0.9803464412689209%\n",
      "person: 0.6700149774551392%\n",
      "chair: 0.5471654534339905%\n",
      "1 detections recorded at 2015-01-03 08:02:45\n",
      "person: 0.978578507900238%\n",
      "1 detections recorded at 2015-01-03 08:02:48\n",
      "person: 0.9220980405807495%\n",
      "1 detections recorded at 2015-01-03 08:11:18\n",
      "person: 0.9960786700248718%\n",
      "1 detections recorded at 2015-01-03 08:11:21\n",
      "person: 0.9973539113998413%\n",
      "1 detections recorded at 2015-01-03 08:11:24\n",
      "person: 0.9088805913925171%\n",
      "1 detections recorded at 2015-01-03 08:11:33\n",
      "person: 0.9607324004173279%\n",
      "1 detections recorded at 2015-01-03 08:11:36\n",
      "person: 0.9613279104232788%\n",
      "1 detections recorded at 2015-01-03 08:11:39\n",
      "person: 0.9811680316925049%\n",
      "1 detections recorded at 2015-01-03 08:11:42\n",
      "person: 0.9807056784629822%\n",
      "1 detections recorded at 2015-01-03 08:11:45\n",
      "person: 0.7006072998046875%\n",
      "1 detections recorded at 2015-01-03 08:11:48\n",
      "person: 0.9984288811683655%\n",
      "1 detections recorded at 2015-01-03 08:11:51\n",
      "person: 0.9780417084693909%\n",
      "1 detections recorded at 2015-01-03 08:24:51\n",
      "person: 0.7939406037330627%\n",
      "2 detections recorded at 2015-01-03 08:50:18\n",
      "person: 0.9935659766197205%\n",
      "person: 0.9574571847915649%\n",
      "1 detections recorded at 2015-01-03 08:50:39\n",
      "person: 0.9767730236053467%\n",
      "1 detections recorded at 2015-01-03 08:50:42\n",
      "person: 0.8578256964683533%\n",
      "1 detections recorded at 2015-01-03 08:52:03\n",
      "person: 0.9957324862480164%\n",
      "1 detections recorded at 2015-01-03 08:52:15\n",
      "person: 0.6472155451774597%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a58ebaaa4334708a9baf800601bac56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2015-01-04 00:00:00 progress:', max=16680), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 detections recorded at 2015-01-04 08:01:06\n",
      "chair: 0.8469684720039368%\n"
     ]
    }
   ],
   "source": [
    "for day_directory in tqdm_notebook(day_directories, desc='Days:'):\n",
    "    '''\n",
    "    print('------------------------------')\n",
    "    print('>>> Processing images for {}'.format(day_directory))\n",
    "    '''\n",
    "    day_dir_path = os.path.join(disk_path, day_directory)\n",
    "    images = sorted([image for image in os.listdir(day_dir_path) if not image.startswith('.')])\n",
    "    \n",
    "    date = datetime.strptime(day_directory,'%m-%d-%Y')\n",
    "    start_datetime = datetime.strptime(day_directory+' '+start_time,'%m-%d-%Y %H:%M')\n",
    "    \n",
    "    background = None # Initialise with no background\n",
    "    \n",
    "    num_images = len(images) # Get amount of images for progress bar\n",
    "        \n",
    "    for image in tqdm_notebook(images, desc='{} progress:'.format(date)):\n",
    "        \n",
    "        image_path = os.path.join(day_dir_path, image)\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Reduce image size to 1%\n",
    "        thumb = cv2.resize(img, None, fx=.1, fy=.1, interpolation = cv2.INTER_AREA)\n",
    "        thumb = cv2.cvtColor(thumb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if background is None: # Initialise background for first pass\n",
    "            background = thumb\n",
    "            \n",
    "        delta = cv2.absdiff(background, thumb)\n",
    "        thresh = cv2.threshold(delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        pixel_diff = cv2.sumElems(thresh)[0] # Need to check that this is the absolute difference\n",
    "        \n",
    "        if pixel_diff > img.size*trigger:\n",
    "            \n",
    "            # Extract frame number from imaga path\n",
    "            image_index = [int(s) for s in list(image) if s.isdigit()]\n",
    "            image_index = ''.join(str(x) for x in image_index) \n",
    "            image_index = int(image_index)\n",
    "            \n",
    "            # Calculate time stamp of frame\n",
    "            time_delta = timedelta(seconds=(frame_step*image_index))\n",
    "            time_stamp = start_datetime + time_delta\n",
    "            \n",
    "            if verbose:\n",
    "                '''\n",
    "                print('---------------')\n",
    "                print(image) \n",
    "                print('Movement detected at {} with pixel delta of {}:'.format(str(time_stamp), pixel_diff))\n",
    "                '''\n",
    "                \n",
    "                if pixel_diff < warning_trigger:\n",
    "                    f, axarr = plt.subplots(1,3, figsize=(15,5))\n",
    "                    axarr[0].imshow(background)\n",
    "                    axarr[1].imshow(thresh)\n",
    "                    axarr[2].imshow(thumb)\n",
    "                    plt.show()\n",
    "\n",
    "            # Object Detection\n",
    "            #PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "            #TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}.jpg'.format(i)) for i in range(1, 20) ]\n",
    "\n",
    "            # Size, in inches, of the output images.\n",
    "            IMAGE_SIZE = (18,12)\n",
    "            \n",
    "            with detection_graph.as_default():\n",
    "              with tf.Session(graph=detection_graph) as sess:\n",
    "                \n",
    "                # Definite input and output Tensors for detection_graph\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                # Each box represents a part of the image where a particular object was detected.\n",
    "                detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Each score represent how level of confidence for each of the objects.\n",
    "                # Score is shown on the result image, together with the class label.\n",
    "                detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                \n",
    "                image = Image.open(image_path)\n",
    "                #print('Image {} Loaded'.format(image_path))\n",
    "                \n",
    "                # the array based representation of the image will be used later in order to prepare the\n",
    "                # result image with boxes and labels on it.\n",
    "                #image_np = load_image_into_numpy_array(image)\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(img, axis=0)\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                # Select observations scored above threshold (default 0.5)\n",
    "                boxes = boxes[scores>detection_threshold]\n",
    "                classes = classes[scores>detection_threshold]\n",
    "                scores = scores[scores>detection_threshold]\n",
    "                num = len(classes)\n",
    "                if num:\n",
    "                    record = (time_stamp, (boxes, scores, classes, num))\n",
    "                    trigger_record.append(record) # Add to record\n",
    "                    print('{} detections recorded at {}'.format(num, str(time_stamp)))\n",
    "                    for c, s in zip(classes, scores):\n",
    "                        print('{}: {}%'.format(category_index[c]['name'], s))\n",
    "                # Visualization of the results of a detection.\n",
    "                '''\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "                    '''\n",
    "                #plt.figure(figsize=IMAGE_SIZE)\n",
    "                #plt.imshow(image_np)\n",
    "                #SAVE_IMAGE_PATH = os.path.join(PATH_TO_TEST_IMAGES_DIR, 'bbox{}.jpg'.format(index))\n",
    "                #plt.savefig(SAVE_IMAGE_PATH)\n",
    "                #print(SAVE_IMAGE_PATH + ' saved.')\n",
    "            \n",
    "            if len(trigger_record) > 20:\n",
    "                break\n",
    "            \n",
    "        #i = int(100*index/(num_images-1))\n",
    "        '''\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write('Movement detected at {} with pixel delta of {}:'.format(str(time_stamp), pixel_diff))\n",
    "        sys.stdout.write(\"[%-100s] %d%%\" % ('='*i, i))\n",
    "        sys.stdout.flush()\n",
    "        '''\n",
    "        background = thumb # Set background for next frame        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 0.9611889123916626% at 2015-01-03 08:00:45\n",
      "person: 0.9961543679237366% at 2015-01-03 08:01:36\n",
      "person: 0.9777339100837708% at 2015-01-03 08:01:36\n",
      "person: 0.9081301689147949% at 2015-01-03 08:01:36\n",
      "person: 0.7179996967315674% at 2015-01-03 08:01:36\n",
      "person: 0.9993106126785278% at 2015-01-03 08:01:39\n",
      "person: 0.9560275077819824% at 2015-01-03 08:01:39\n",
      "person: 0.7579991817474365% at 2015-01-03 08:01:39\n",
      "person: 0.5621638298034668% at 2015-01-03 08:01:39\n",
      "person: 0.9841618537902832% at 2015-01-03 08:02:45\n",
      "person: 0.9181041121482849% at 2015-01-03 08:02:48\n",
      "person: 0.9979661703109741% at 2015-01-03 08:11:18\n",
      "person: 0.9977293610572815% at 2015-01-03 08:11:21\n",
      "person: 0.8208078145980835% at 2015-01-03 08:11:24\n",
      "person: 0.9628744125366211% at 2015-01-03 08:11:33\n",
      "person: 0.9804023504257202% at 2015-01-03 08:11:36\n",
      "person: 0.9813427329063416% at 2015-01-03 08:11:39\n",
      "person: 0.9770221710205078% at 2015-01-03 08:11:42\n",
      "person: 0.86475670337677% at 2015-01-03 08:11:45\n",
      "person: 0.999150276184082% at 2015-01-03 08:11:48\n",
      "person: 0.9915336966514587% at 2015-01-03 08:11:51\n",
      "person: 0.7701256275177002% at 2015-01-03 08:24:51\n",
      "person: 0.9969802498817444% at 2015-01-03 08:50:18\n",
      "person: 0.9927305579185486% at 2015-01-03 08:50:18\n",
      "person: 0.9899281859397888% at 2015-01-03 08:50:39\n",
      "person: 0.9043036103248596% at 2015-01-03 08:50:42\n",
      "person: 0.6336838006973267% at 2015-01-03 08:50:42\n",
      "person: 0.9985384941101074% at 2015-01-03 08:52:03\n",
      "person: 0.7871893644332886% at 2015-01-03 08:52:15\n",
      "chair: 0.9090482592582703% at 2015-01-04 08:01:06\n"
     ]
    }
   ],
   "source": [
    "for r in trigger_record:\n",
    "    for c, s in zip(r[1][2], r[1][1]):\n",
    "        print('{}: {}% at {}'.format(category_index[c]['name'], s, r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motion_detections = pd.DataFrame({'timestamp':trigger_record})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = min(motion_detections.timestamp).replace(hour=0, minute=0, second=0).to_pydatetime()\n",
    "end_time = max(motion_detections.timestamp).replace(hour=0, minute=0, second=0).to_pydatetime() + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_range = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "time_range_counter = pd.DataFrame({'timestamps':all_range, 'counter':0}).set_index('timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for detection in motion_detections.timestamp:\n",
    "    detection_time = detection.replace(minute=0, second=0)\n",
    "    time_range_counter.counter[detection_time] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_colors = 'b'\n",
    "time_range_counter.plot(kind='bar',\n",
    "             color=my_colors,\n",
    "             alpha=0.5,\n",
    "             figsize=(16,8),\n",
    "             title='Motion Detections')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hour_motion_detections = motion_detections.groupby(motion_detections.timestamp.dt.hour).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_colors = 'r'\n",
    "hour_motion_detections.plot(kind='bar',\n",
    "             color=my_colors,\n",
    "             alpha=0.5,\n",
    "             figsize=(16,8),\n",
    "             title='Av. Motion Detections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_index[88.]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(category_index)+1):\n",
    "    try: \n",
    "        print(category_index[i]['name'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime \n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Object Detection\n",
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# if tf.__version__ < '1.4.0':\n",
    "#   raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inputs/test2\n"
     ]
    }
   ],
   "source": [
    "# Set-up directory\n",
    "# Memory stick = /Volumes/FRED SHONE\n",
    "# Drive = Elements\n",
    "# Test = \n",
    "stick_location = '/Volumes/FRED SHONE' # Memory Stick\n",
    "drive_location = '/Volumes/Elements' # Drive\n",
    "test0 = 'test_inputs/test0'\n",
    "test1 = 'test_inputs/test1'\n",
    "test2 = 'test_inputs/test2'\n",
    "test3 = 'test_inputs/test3'\n",
    "\n",
    "disk_path = test2\n",
    "\n",
    "print(disk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01-03-2015']\n"
     ]
    }
   ],
   "source": [
    "# Access daily sub-directories of images\n",
    "\n",
    "folders = os.listdir(disk_path) # Assumes sorting by name is ok - but this won't work for changes in year\n",
    "\n",
    "# Filter for days by trying to convert to datetime\n",
    "\n",
    "day_directories = []\n",
    "dates = []\n",
    "for folder in folders:\n",
    "    try: \n",
    "        date = datetime.strptime(folder, '%d-%m-%Y')\n",
    "        day_directories.append(folder)\n",
    "        dates.append(date)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "day_directories = [x for y, x in sorted(zip(dates, day_directories))]\n",
    "    \n",
    "print(day_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-03-2015: 100 images\n",
      "frame rate assumed to be ~0.001851851851851852 frames per second\n"
     ]
    }
   ],
   "source": [
    "# Check for number of images in day directories\n",
    "\n",
    "for day_directory in day_directories:\n",
    "    day_dir_path = os.path.join(disk_path, day_directory)\n",
    "    image_paths = os.listdir(day_dir_path)\n",
    "    image_paths = sorted([image for image in os.listdir(day_dir_path) if not image.startswith('.')])\n",
    "    image_count = len(image_paths)\n",
    "    print('{}: {} images'.format(day_directory, image_count))   \n",
    "    #Wilkins building listed as opening hours from 8am to 11pm = 15 hours\n",
    "    frame_rate = image_count/(15*60*60)\n",
    "    print('frame rate assumed to be ~{} frames per second'.format(frame_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo = {'sd_mobilenet_v1_coco' : 'ssd_mobilenet_v1_coco_2018_01_28',\n",
    "            'sd_mobilenet_v2_coco' : 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "            'ssdlite_mobilenet_v2_coco' : 'ssdlite_mobilenet_v2_coco_2018_05_09',\n",
    "            'ssd_inception_v2_coco' : 'ssd_inception_v2_coco_2018_01_28',\n",
    "            'faster_rcnn_inception_v2_coco' : 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "            'faster_rcnn_resnet50_coco' : 'faster_rcnn_resnet50_coco_2018_01_28',\n",
    "            'faster_rcnn_resnet50_lowproposals_coco' : 'faster_rcnn_resnet50_lowproposals_coco_2018_01_28',\n",
    "            'rfcn_resnet101_coco' : 'rfcn_resnet101_coco_2018_01_28',\n",
    "            'faster_rcnn_resnet101_coco' : 'faster_rcnn_resnet101_coco_2018_01_28',\n",
    "            'faster_rcnn_resnet101_lowproposals_coco' : 'faster_rcnn_resnet101_lowproposals_coco_2018_01_28'}\n",
    "\n",
    "mask_zoo = {'mask_rcnn_inception_v2_coco' : 'mask_rcnn_inception_v2_coco_2018_01_28'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = 'ssd_inception_v2_coco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare paths\n",
    "MODEL_NAME = model_zoo.get(model_choice)\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "# Load label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Frozen model into memory\n",
    "def load_model(model_name, location = 'object_detection'):\n",
    "\n",
    "    # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "    ckpt_path = os.path.join(location, model_name, 'frozen_inference_graph.pb')\n",
    "    \n",
    "    # Download if necessary\n",
    "    if not os.path.isfile(ckpt_path):\n",
    "        print('>>> Cannot find frozen model')\n",
    "        download_model(model_name, location)\n",
    "    \n",
    "    print('Loading frozen model: {}'.format(ckpt_path))\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "      od_graph_def = tf.GraphDef()\n",
    "      with tf.gfile.GFile(ckpt_path, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    print('Done')\n",
    "    return detection_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Model\n",
    "def download_model(model_name, location = 'object_detection'):\n",
    "\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    download_base = 'http://download.tensorflow.org/models/object_detection'\n",
    "    download_path = os.path.join(download_base, model_file)\n",
    "    model_path = os.path.join(location, model_file)\n",
    "    \n",
    "    # Download if necessary\n",
    "    if not os.path.isfile(model_path):\n",
    "        \n",
    "        print('Downloading: {}'.format(model_file))\n",
    "        opener = urllib.request.URLopener()\n",
    "        opener.retrieve(download_path, model_path)\n",
    "        \n",
    "    print('Extracting frozen inference graph from: {}'.format(model_path))\n",
    "    tar_file = tarfile.open(model_path)\n",
    "    for file in tar_file.getmembers():\n",
    "      file_name = os.path.basename(file.name)\n",
    "      if 'frozen_inference_graph.pb' in file_name:\n",
    "        tar_file.extract(file, os.path.join(os.getcwd(), location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frozen model: object_detection/ssd_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "detection_graph = load_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up motion detector\n",
    "sensitivity = 0.0001 # Total pixel difference to trigger motion detection\n",
    "warning_trigger = 10000 # Total pixel difference to trigger verbose image plot\n",
    "\n",
    "verbose = False \n",
    "start_time = '08:00' # Assumes camera turned on at 8am every day\n",
    "frame_step = 3 # Seconds\n",
    "\n",
    "detect_objects = True\n",
    "detection_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_image(img):\n",
    "    # Reduce image size to 1%\n",
    "    thumb = cv2.resize(img, None, fx=.1, fy=.1, interpolation = cv2.INTER_AREA)\n",
    "    thumb = cv2.cvtColor(thumb, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    return thumb\n",
    "\n",
    "def motion_trigger(sensitivity, thumb, background):\n",
    "\n",
    "    if background is None: # Initialise background for first pass\n",
    "        background = thumb\n",
    "\n",
    "    delta = cv2.absdiff(background, thumb)\n",
    "    thresh = cv2.threshold(delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    pixel_diff = cv2.sumElems(thresh)[0]\n",
    "    \n",
    "    if pixel_diff > thumb.size*sensitivity:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Detection\n",
    "def detection(sess, detection_graph, img, frame):\n",
    "\n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num) = sess.run(\n",
    "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "        feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    # Select observations scored above threshold (default 0.5)\n",
    "    boxes = boxes[scores>detection_threshold]\n",
    "    classes = classes[scores>detection_threshold]\n",
    "    scores = scores[scores>detection_threshold]\n",
    "    num = len(classes)\n",
    "    if num:\n",
    "        detection_record = frame\n",
    "\n",
    "    '''\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "        '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(model_id, disk_path, day_directories):\n",
    "    \n",
    "    detection_graph = load_model(model_id)\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "\n",
    "            for day_directory in tqdm_notebook(day_directories, desc='Days:'):\n",
    "\n",
    "                day_dir_path = os.path.join(disk_path, day_directory)\n",
    "                images = sorted([image for image in os.listdir(day_dir_path) if not image.startswith('.')])\n",
    "\n",
    "                date = datetime.strptime(day_directory,'%m-%d-%Y')\n",
    "                start_datetime = datetime.strptime(day_directory+' '+start_time,'%m-%d-%Y %H:%M')\n",
    "\n",
    "                background = None # Initialise with no background\n",
    "\n",
    "                for image in tqdm_notebook(images, desc='{} progress:'.format(date)):\n",
    "\n",
    "                    image_path = os.path.join(day_dir_path, image)\n",
    "                    img = cv2.imread(image_path)\n",
    "\n",
    "                    # Extract frame number from image path\n",
    "                    image_index = [int(s) for s in list(image) if s.isdigit()]\n",
    "                    image_index = ''.join(str(x) for x in image_index) \n",
    "                    image_index = int(image_index)\n",
    "\n",
    "                    # Calculate time stamp of frame\n",
    "                    time_delta = timedelta(seconds=(frame_step*image_index))\n",
    "                    time_stamp = start_datetime + time_delta\n",
    "                    \n",
    "                    # Trigger ##############################################\n",
    "                    thumb =  trigger_image(img)\n",
    "                    \n",
    "                    if motion_trigger(sensitivity, thumb, background):\n",
    "                        \n",
    "                        detection(sess, detection_graph, img, time_stamp)\n",
    "\n",
    "                    background = thumb # Set background for next frame\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frozen model: object_detection/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9677544015437696415eb216ea3583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Days:', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fb6871a0904a53ac327e9cb3b6b55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2015-01-03 00:00:00 progress:'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c54444a241e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcategory_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_category_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisk_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday_directories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-9581dc62b684>\u001b[0m in \u001b[0;36mtrack\u001b[0;34m(model_id, disk_path, day_directories)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;31m# Extract frame number from image path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, model_id in model_zoo.items():\n",
    "\n",
    "    # List of the strings that is used to add correct label for each box.\n",
    "    PATH_TO_LABELS = os.path.join('object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "    NUM_CLASSES = 10 #90\n",
    "\n",
    "    # Load label map\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    track(model_id, disk_path, day_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a4e9946dcace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_records_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "len(detection_records_all[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-8fc3e26b30dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_times(records):\n",
    "    if len(records) > 1:\n",
    "        for record in records:\n",
    "            total = 0.\n",
    "            for time in record:\n",
    "                total += time.microseconds/1000000\n",
    "                total += time.seconds\n",
    "            print(total / len(record))\n",
    "    else:\n",
    "        total = 0.\n",
    "        for time in records:\n",
    "            total += time.microseconds/1000000\n",
    "            total += time.seconds\n",
    "        print(total / len(records))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_times_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-53dbbe08de3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarize_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_times_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-0ba3bcb48dfd>\u001b[0m in \u001b[0;36msummarize_times\u001b[0;34m(records)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmicroseconds\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "summarize_times(detection_times_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sd_mobilenet_v1_coco' : 'ssd_mobilenet_v1_coco_2018_01_28',\n",
    "'sd_mobilenet_v2_coco' : 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "'ssdlite_mobilenet_v2_coco' : 'ssdlite_mobilenet_v2_coco_2018_05_09',\n",
    "'ssd_inception_v2_coco' : 'ssd_inception_v2_coco_2018_01_28',\n",
    "'faster_rcnn_inception_v2_coco' : 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "'faster_rcnn_resnet50_coco' : 'faster_rcnn_resnet50_coco_2018_01_28',\n",
    "            \n",
    "3.51341744\n",
    "5.644824460000002\n",
    "4.08255038\n",
    "6.199835679999998\n",
    "9.05841078\n",
    "\n",
    "within session:\n",
    "\n",
    "0.18028956249999994\n",
    "0.32623807812499994\n",
    "0.16248326562499996\n",
    "0.426629359375\n",
    "2.671003390625\n",
    "\n",
    "v small:\n",
    "\n",
    "0.17886360937500004\n",
    "0.32321753125\n",
    "0.18154984375000005\n",
    "0.3944962343749999\n",
    "2.41329240625\n",
    "\n",
    "no resize:\n",
    "0.20466068749999997\n",
    "0.2902670468750001\n",
    "0.2412987656249999\n",
    "0.43082529687500004\n",
    "2.2224505624999997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trigger_records_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_records_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops = sess.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for op in ops:\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigger_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in trigger_record:\n",
    "    for c, s in zip(r[1][2], r[1][1]):\n",
    "        print('{}: {}% at {}'.format(category_index[c]['name'], s, r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motion_detections = pd.DataFrame({'timestamp':trigger_record})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = min(motion_detections.timestamp).replace(hour=0, minute=0, second=0).to_pydatetime()\n",
    "end_time = max(motion_detections.timestamp).replace(hour=0, minute=0, second=0).to_pydatetime() + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_range = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "time_range_counter = pd.DataFrame({'timestamps':all_range, 'counter':0}).set_index('timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for detection in motion_detections.timestamp:\n",
    "    detection_time = detection.replace(minute=0, second=0)\n",
    "    time_range_counter.counter[detection_time] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_colors = 'b'\n",
    "time_range_counter.plot(kind='bar',\n",
    "             color=my_colors,\n",
    "             alpha=0.5,\n",
    "             figsize=(16,8),\n",
    "             title='Motion Detections')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hour_motion_detections = motion_detections.groupby(motion_detections.timestamp.dt.hour).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_colors = 'r'\n",
    "hour_motion_detections.plot(kind='bar',\n",
    "             color=my_colors,\n",
    "             alpha=0.5,\n",
    "             figsize=(16,8),\n",
    "             title='Av. Motion Detections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_index[88.]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(category_index)+1):\n",
    "    try: \n",
    "        print(category_index[i]['name'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'person'},\n",
       " 2: {'id': 2, 'name': 'bicycle'},\n",
       " 3: {'id': 3, 'name': 'car'},\n",
       " 4: {'id': 4, 'name': 'motorcycle'},\n",
       " 5: {'id': 5, 'name': 'airplane'},\n",
       " 6: {'id': 6, 'name': 'bus'},\n",
       " 7: {'id': 7, 'name': 'train'},\n",
       " 8: {'id': 8, 'name': 'truck'},\n",
       " 9: {'id': 9, 'name': 'boat'},\n",
       " 10: {'id': 10, 'name': 'traffic light'}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
